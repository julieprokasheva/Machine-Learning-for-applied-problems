{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd824a5",
   "metadata": {},
   "source": [
    "### Assignment 1\n",
    "\n",
    "Implement a random forest sampling algorithm (bootstrap aggregating + random subspace method). Write an implementation of three functions (bootstrap_sample, random_subspace, get_subsample) and combine them into the sample class, which returns some random subsample from the sample, suitable for training one of the trees in the random forest ensemble.\n",
    "\n",
    "Note: Note that features in the final subsample must not be duplicated. Use only the tools implemented in numpy.random, setting random_state=42 wherever necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d4ea9d",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "\n",
    "1. bootstrap_sample is a method that works as follows: It choses random object from the dataset, remembers the id and repeates this operation for N_obj times, where N_obj is a number of ogbects in dataset. Then it returns all unique written values. Thus, probability for each object to be returned is approximately 0.62.\n",
    "\n",
    "\n",
    "2. random_subspace returns id of randomly chosen features from dataset.\n",
    "\n",
    "\n",
    "3. get_subsample returns subsample of given dataset based on bootstrap sampling and random_subspace methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac91f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "class sample(object):\n",
    "    def __init__(self, X, n_subspace):\n",
    "        self.idx_subspace = self.random_subspace(X, n_subspace)\n",
    "\n",
    "    def __call__(self, X, y):\n",
    "        idx_obj = self.bootstrap_sample(X)\n",
    "        X_sampled, y_sampled = self.get_subsample(X, y, self.idx_subspace, idx_obj)\n",
    "        return X_sampled, y_sampled\n",
    "\n",
    "    @staticmethod\n",
    "    def bootstrap_sample(X):\n",
    "        idx_obj = np.unique([ np.random.choice(X.shape[0], size=1) for _ in range(X.shape[0]) ])\n",
    "        return idx_obj\n",
    "    \n",
    "    @staticmethod \n",
    "    def random_subspace(X, n_subspace):\n",
    "        idx_subspace = np.random.choice(X.shape[1], size=n_subspace, replace=False)\n",
    "        return idx_subspace\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_subsample(X, y, idx_subspace, idx_obj):\n",
    "        X_sample, y_sample = X[:, idx_subspace][idx_obj, :], y[idx_obj]\n",
    "        return X_sample, y_sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be276a5",
   "metadata": {},
   "source": [
    "An example of execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bd8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "Y = np.array([1, 2, 3])\n",
    "\n",
    "for _ in range(3):\n",
    "    s = sample(X, 2)\n",
    "    bootstrap_indices = s.bootstrap_sample(X)\n",
    "    X_sampled, y_sampled = s(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3f1979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows (objects) from given array X\n",
    "bootstrap_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3c8de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns (features) from given array X\n",
    "s.idx_subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f314d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2],\n",
       "       [6, 5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output array\n",
    "X_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82ebae98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corresponding responses output\n",
    "y_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b90ae",
   "metadata": {},
   "source": [
    "### Assignment 2\n",
    "\n",
    "1. Write the random_forest class to solve the classification problem based on the Fisher Iris dataset (sklearn.datasets.load_iris), which takes the n_estimators, max_depth, subspaces_dim and random_state arguments as input to the constructor. Define the .fit() and .predict() methods.\n",
    "\n",
    "2. Select the hyperparameters on which your algorithm gets the best quality (in terms of the accuracy metric, the proportion of correct answers) on the test set with the parameter test_size=0.3, set them as global variables N_ESTIMATORS, MAX_DEPTH, SUBSPACE_DIM.\n",
    "\n",
    "Note: The use of the sklearn.ensemble.RandomForestClassifier class is prohibited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be63ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e51f1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa49bf5",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "Here we implement a Random Forest Classifier algorithm. \n",
    "\n",
    "1. In fit() method the several base algorithms (DecisionTreeClassifier) are trained using sampling algorithm above. So that we have $n$=n_estimators different models.\n",
    "\n",
    "2. In predict() method each trained model predicts classes of objects and wote for each object. Method returns the most popular class among models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79aed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_forest(object):\n",
    "    def __init__(self, n_estimators: int, max_depth: int, subspaces_dim: int, random_state: int):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.subspaces_dim = subspaces_dim\n",
    "        self.random_state = random_state\n",
    "        self._estimators = []\n",
    "        self.subspace_idx = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        for i in range(self.n_estimators):\n",
    "            s = sample(X, self.subspaces_dim)\n",
    "            X_sample, y_sample = s(X, y) \n",
    "            self.subspace_idx.append(s.idx_subspace)\n",
    "            \n",
    "            estimator = DecisionTreeClassifier(max_depth=self.max_depth, random_state=self.random_state).fit(X_sample, y_sample)\n",
    "            self._estimators.append(estimator)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        predictions = np.array([ self._estimators[i].predict(X[:, self.subspace_idx[i]]) for i in range(self.n_estimators) ])\n",
    "        y_pred = []\n",
    "        for i in range(X.shape[0]):\n",
    "            y_predict, counts = np.unique(predictions[:, i], return_counts=True)\n",
    "            y_pred.append(y_predict[np.argmax(counts)])\n",
    "            \n",
    "        return np.array(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2302ee",
   "metadata": {},
   "source": [
    "Here we train RandomFroest using iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d32e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_iris(return_X_y=True)\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce249a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_ESTIMATORS = 3\n",
    "MAX_DEPTH = 2\n",
    "SUBSPACE_DIM = 2\n",
    "\n",
    "model = random_forest(N_ESTIMATORS, MAX_DEPTH, SUBSPACE_DIM, 42)\n",
    "model.fit(X_train, y_train)\n",
    "            \n",
    "y_pred = model.predict(x_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
