{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb52b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49fb59",
   "metadata": {},
   "source": [
    "### Assignment 1\n",
    "\n",
    "Implement the calculation of binary classification quality metrics (precision, recall, and f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9030e4",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac91d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    TP = (y_pred * y_true).sum()\n",
    "    FP = (y_pred * (1 - y_true)).sum()\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    TP = (y_pred * y_true).sum()\n",
    "    FN = ((1 - y_pred) * y_true).sum()\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    pr = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * pr * rec / (pr + rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795d717",
   "metadata": {},
   "source": [
    "### Assignment 2\n",
    "\n",
    "Solve the binary classification problem on the breast_cancer dataset using 4 different algorithms:\n",
    "\n",
    "     Decision Tree (1)\n",
    "     Logistic Regression (2)\n",
    "     KNN (3)\n",
    "     SVC (4)\n",
    "\n",
    "Find algorithms with the best ROC AUC score and PR AUC score. As an answer, write the number $ab$, where $a$ is the best algorithm in terms of ROC AUC score, and $b$ is the best algorithm in terms of PR AUC score.\n",
    "\n",
    "Do not forget to carry out additional data preprocessing by bringing them to a single scale using the StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e40f157",
   "metadata": {},
   "source": [
    "### Solution 2\n",
    "\n",
    "Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035cb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train, X_test = sc.transform(X_train), sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409401e",
   "metadata": {},
   "source": [
    "Model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97931cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "svm = SVC(probability=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82413884",
   "metadata": {},
   "source": [
    "Here we calculate the ROC AUC score and PR AUC score for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37cc51c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 0.9438, 2: 0.9828, 3: 0.9544, 4: 0.9749},\n",
       " {1: 0.9736, 2: 0.9988, 3: 0.9864, 4: 0.998})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [tree, lr, knn, svm]\n",
    "scores, predictions, roc_score, auc_score = {}, {}, {}, {}\n",
    "\n",
    "i = 1\n",
    "for model in models:\n",
    "    scores[i] = model.predict_proba(X_test)[:,1]\n",
    "    predictions[i] = model.predict(X_test)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, scores[i])\n",
    "    roc_score[i] = roc_auc_score(y_test, predictions[i]).round(4)\n",
    "    auc_score[i] = auc(recall, precision).round(4)\n",
    "    i += 1\n",
    "\n",
    "roc_score, auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2e8027",
   "metadata": {},
   "source": [
    "We can see that Logistic Regression is the best one according to both ROC and PR AUC scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25a3c8",
   "metadata": {},
   "source": [
    "### Assignment 3\n",
    "\n",
    "write functions to implement micro and macro averaging of metrics in multiclass classification.\n",
    "\n",
    "You need to implement the following functions:\n",
    "\n",
    "     err_table:        for compiling the error matrix for the multiclass case\n",
    "     micro_precision:  for micro-averaging precision\n",
    "     macro_precision:  for macro-averaging precision\n",
    "     micro_recall:     for recall microaveraging\n",
    "     macro_recall:     for recall macroaveraging\n",
    "     micro_f1:         for micro-averaging the f1-measure\n",
    "     macro_f1:         for macro averaging f1-measure\n",
    "\n",
    "As part of the solution of this task, you can only use the numpy framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16633648",
   "metadata": {},
   "source": [
    "### Solution 3\n",
    "\n",
    "1. Error_matrix\n",
    "\n",
    "    The rows of error_matrix matrix will symbolize the true classes, and the columns - the predicted ones. The number N in the matrix cell ij will be interpreted as follows:\n",
    "\n",
    "        - This algorithm classified N objects belonging to class i as objects of class j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8083288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_table(y_true: np.array, y_pred: np.array):\n",
    "    classes = np.unique(y_true)\n",
    "    n = classes.size\n",
    "    \n",
    "    confus_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        ind = np.where(y_true == classes[i])[0]\n",
    "        y_examined = y_pred[ind]\n",
    "        \n",
    "        for j in range(n):\n",
    "            confus_matrix[i,j] = np.where(y_examined == classes[j])[0].size\n",
    "        \n",
    "    return confus_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0251c1",
   "metadata": {},
   "source": [
    "Additional methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143c6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrices(err_table: np.array):\n",
    "    n = err_table.shape[0]\n",
    "    TP, FP, FN = np.zeros((n)),  np.zeros((n)),  np.zeros((n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        TP[i] = err_table[i, i]\n",
    "        FP[i] = err_table[:, i].sum() - TP[i]\n",
    "        FN[i] = err_table[i, :].sum() - TP[i]\n",
    "        \n",
    "    return TP, FP, FN\n",
    "\n",
    "\n",
    "def precision(TP, FP):\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def recall(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def f1(prec, rec):\n",
    "    return 2*(prec * rec)/(prec + rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9b9de",
   "metadata": {},
   "source": [
    "2. Micro & macro precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00a1d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_precision(err_table: np.array):\n",
    "    TP, FP,  _ = metrices(err_table)\n",
    "    return precision(TP.mean(), FP.mean())\n",
    "\n",
    "def macro_precision(err_table: np.array):\n",
    "    TP, FP, _ = metrices(err_table)\n",
    "    return precision(TP, FP).mean()\n",
    "\n",
    "\n",
    "def micro_recall(err_table: np.array):\n",
    "    TP, _, FN = metrices(err_table)\n",
    "    return recall(TP.mean(), FN.mean())\n",
    "\n",
    "def macro_recall(err_table: np.array):\n",
    "    TP, _, FN = metrices(err_table)\n",
    "    return recall(TP, FN).mean()\n",
    "\n",
    "\n",
    "def micro_f1(err_table: np.array):\n",
    "    micro_pr, micro_rec = micro_precision(err_table), micro_recall(err_table)\n",
    "    return f1(micro_pr, micro_rec)\n",
    " \n",
    "def macro_f1(err_table: np.array):\n",
    "    TP, FP, FN = metrices(err_table)\n",
    "    precis, rec = precision(TP, FP), recall(TP, FN)\n",
    "    \n",
    "    f1_score = f1(precis, rec)\n",
    "    return f1_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f510e21d",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b017c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 0.],\n",
       "       [3., 1., 0.],\n",
       "       [1., 1., 2.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2])\n",
    "y_pred = np.array([0, 0, 1, 1, 0, 1, 0, 0, 2, 1, 0, 2])\n",
    "\n",
    "ErTable = err_table(y_true, y_pred)\n",
    "\n",
    "ErTable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61888017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4167, 0.5278)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_precision(ErTable).round(4), macro_precision(ErTable).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "524ea81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4167, 0.4167)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_recall(ErTable).round(4), macro_recall(ErTable).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3678e608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4389, 0.4167)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(ErTable).round(4), micro_f1(ErTable).round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
